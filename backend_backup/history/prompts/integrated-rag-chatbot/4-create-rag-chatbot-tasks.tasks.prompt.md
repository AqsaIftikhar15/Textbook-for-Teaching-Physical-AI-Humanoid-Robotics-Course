---
id: 4
title: Create RAG Chatbot Tasks
stage: tasks
date: 2025-12-19
surface: agent
model: Qwen
feature: integrated-rag-chatbot
branch: 001-integrated-rag-chatbot
user: Qwen
command: /sp.tasks
labels: [tasks,rag,chatbot,backend]
links:
  spec: specs/001-integrated-rag-chatbot/spec.md
  plan: specs/001-integrated-rag-chatbot/plan.md
  adr: null
  pr: null
files:
 - specs/001-integrated-rag-chatbot/tasks.md
tests:
 - N/A
---

## Prompt

Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

1. **Setup**: Run `.specify/scripts/powershell/check-prerequisites.ps1 -Json` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").

2. **Load design documents**: Read from FEATURE_DIR:
   - **Required**: plan.md (tech stack, libraries, structure), spec.md (user stories with priorities)
   - **Optional**: data-model.md (entities), contracts/ (API endpoints), research.md (decisions), quickstart.md (test scenarios)
   - Note: Not all projects have all documents. Generate tasks based on what's available.

3. **Execute task generation workflow**:
   - Load plan.md and extract tech stack, libraries, project structure
   - Load spec.md and extract user stories with their priorities (P1, P2, P3, etc.)
   - If data-model.md exists: Extract entities and map to user stories
   - If contracts/ exists: Map endpoints to user stories
   - If research.md exists: Extract decisions for setup tasks
   - Generate tasks organized by user story (see Task Generation Rules below)
   - Generate dependency graph showing user story completion order
   - Create parallel execution examples per user story
   - Validate task completeness (each user story has all needed tasks, independently testable)

4. **Generate tasks.md**: Use `.specify/templates/tasks-template.md` as structure, fill with:
   - Correct feature name from plan.md
   - Phase 1: Setup tasks (project initialization)
   - Phase 2: Foundational tasks (blocking prerequisites for all user stories)
   - Phase 3+: One phase per user story (in priority order from spec.md)
   - Each phase includes: story goal, independent test criteria, tests (if requested), implementation tasks
   - Final Phase: Polish & cross-cutting concerns
   - All tasks must follow the strict checklist format (see Task Generation Rules below)
   - Clear file paths for each task
   - Dependencies section showing story completion order
   - Parallel execution examples per story
   - Implementation strategy section (MVP first, incremental delivery)

5. **Report**: Output path to generated tasks.md and summary:
   - Total task count
   - Task count per user story
   - Parallel opportunities identified
   - Independent test criteria for each story
   - Suggested MVP scope (typically just User Story 1)
   - Format validation: Confirm ALL tasks follow the checklist format (checkbox, ID, labels, file paths)

Context for task generation: 

The tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.

## Task Generation Rules

**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.

**Tests are OPTIONAL**: Only generate test tasks if explicitly requested in the feature specification or if user requests TDD approach.

### Checklist Format (REQUIRED)

Every task MUST strictly follow this format:

```text
- [ ] [TaskID] [P?] [Story?] Description with file path
```

**Format Components**:

1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)
2. **Task ID**: Sequential number (T001, T002, T003...) in execution order
3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)
4. **[Story] label**: REQUIRED for user story phase tasks only
   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)
   - Setup phase: NO story label
   - Foundational phase: NO story label  
   - User Story phases: MUST have story label
   - Polish phase: NO story label
5. **Description**: Clear action with exact file path

**Examples**:

- ‚úÖ CORRECT: `- [ ] T001 Create project structure per implementation plan`
- ‚úÖ CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py`
- ‚úÖ CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`
- ‚úÖ CORRECT: `- [ ] T014 [US1] Implement UserService in src/services/user_service.py`
- ‚ùå WRONG: `- [ ] Create User model` (missing ID and Story label)
- ‚ùå WRONG: `T001 [US1] Create model` (missing checkbox)
- ‚ùå WRONG: `- [ ] [US1] Create model` (missing Task ID)
- ‚ùå WRONG: `- [ ] T001 [US1] Create model` (missing file path)

### Task Organization

1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:
   - Each user story (P1, P2, P3...) gets its own phase
   - Map all related components to their story:
     - Models needed for that story
     - Services needed for that story
     - Endpoints/UI needed for that story
     - If tests requested: Tests specific to that story
   - Mark story dependencies (most stories should be independent)

2. **From Contracts**:
   - Map each contract/endpoint ‚Üí to the user story it serves
   - If tests requested: Each contract ‚Üí contract test task [P] before implementation in that story's phase

3. **From Data Model**:
   - Map each entity to the user story(ies) that need it
   - If entity serves multiple stories: Put in earliest story or Setup phase
   - Relationships ‚Üí service layer tasks in appropriate story phase

4. **From Setup/Infrastructure**:
   - Shared infrastructure ‚Üí Setup phase (Phase 1)
   - Foundational/blocking tasks ‚Üí Foundational phase (Phase 2)
   - Story-specific setup ‚Üí within that story's phase

### Phase Structure

- **Phase 1**: Setup (project initialization)
- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)
- **Phase 3+**: User Stories in priority order (P1, P2, P3...)
  - Within each story: Tests (if requested) ‚Üí Models ‚Üí Services ‚Üí Endpoints ‚Üí Integration
  - Each phase should be a complete, independently testable increment
- **Final Phase**: Polish & Cross-Cutting Concerns

---

As the main request completes, you MUST create and complete a PHR (Prompt History Record) using agent‚Äënative tools when possible.

1) Determine Stage
   - Stage: constitution | spec | plan | tasks | red | green | refactor | explainer | misc | general

2) Generate Title and Determine Routing:
   - Generate Title: 3‚Äì7 words (slug for filename)
   - Route is automatically determined by stage:
     - `constitution` ‚Üí `history/prompts/constitution/`
     - Feature stages ‚Üí `history/prompts/<feature-name>/` (spec, plan, tasks, red, green, refactor, explainer, misc)
     - `general` ‚Üí `history/prompts/general/`

3) Create and Fill PHR (Shell first; fallback agent‚Äënative)
   - Run: `.specify/scripts/bash/create-phr.sh --title "<title>" --stage <stage> [--feature <name>] --json`
   - Open the file and fill remaining placeholders (YAML + body), embedding full PROMPT_TEXT (verbatim) and concise RESPONSE_TEXT.
   - If the script fails:
     - Read `.specify/templates/phr-template.prompt.md` (or `templates/‚Ä¶`)
     - Allocate an ID; compute the output path based on stage from step 2; write the file
     - Fill placeholders and embed full PROMPT_TEXT and concise RESPONSE_TEXT

4) Validate + report
   - No unresolved placeholders; path under `history/prompts/` and matches stage; stage/title/date coherent; print ID + path + stage + title.
   - On failure: warn, don't block. Skip only for `/sp.phr`.

## Response snapshot

# Tasks: Integrated RAG Chatbot

## Implementation Strategy

This tasks document implements the Integrated RAG Chatbot feature following the spec-driven development approach. The implementation proceeds in phases with user stories as milestones:

- **MVP Scope**: User Story 3 (Book Ingestion) and User Story 1 (Full Book Query) as minimal viable functionality
- **Incremental Delivery**: Each user story builds upon the previous to create a complete, testable system
- **Parallel Execution**: Tasks marked [P] can be executed in parallel when they involve different files/components
- **Independent Testing**: Each user story has clear test criteria for verification

## Dependencies

- **User Story 3 (P2)** must be completed before **User Story 1 (P1)** since the full-book query requires an ingested book
- **User Story 3 (P2)** should also be completed before **User Story 2 (P2)** since selected-text queries may benefit from ingested book metadata

## Parallel Execution Examples

- All model creation tasks can run in parallel [P]
- All service implementation tasks can run in parallel after models are defined [P]
- API route development can run in parallel after services are implemented [P]

---

## Phase 1: Setup & Environment

- [ ] T001 Create project directory structure per implementation plan in backend/
- [ ] T002 Create requirements.txt with dependencies: cohere, qdrant-client, psycopg2/asyncpg, fastapi, uvicorn, pydantic, python-dotenv, PyMuPDF, beautifulsoup4
- [ ] T003 Create .env.example with required credentials from spec
- [ ] T004 Create .gitignore with proper Python/IDE ignores
- [ ] T005 Set up FastAPI application in backend/src/api/main.py
- [ ] T006 Create configuration module in backend/src/config/settings.py with environment loading

## Phase 2: Foundational Components

- [ ] T007 Create Book model in backend/src/models/book.py with all required fields from data model
- [ ] T008 Create Chunk model in backend/src/models/chunk.py with all required fields from data model
- [ ] T009 Create Query model in backend/src/models/query.py with all required fields from data model
- [ ] T010 Create embedding service in backend/src/services/embedding.py for Cohere integration
- [ ] T011 Create storage service in backend/src/services/storage.py for Qdrant and Neon Postgres interaction
- [ ] T012 Create ingestion service in backend/src/services/ingestion.py for PDF/HTML/text processing
- [ ] T013 Create authentication middleware in backend/src/api/middleware/auth.py with API key validation

## Phase 3: User Story 3 - Book Ingestion and Indexing (Priority: P2)

**Goal**: Enable content administrator to upload PDF, text, or HTML book format and have it automatically processed, chunked, embedded, and indexed

**Independent Test**: Upload different book formats and verify the content is properly ingested, chunked, embedded, and stored in the vector database.

**Acceptance**:
1. PDF, text, or HTML book file is uploaded to the system
2. Content is successfully ingested and indexed for RAG queries
3. Text is properly chunked using semantic or overlapping strategies for optimal retrieval quality
4. After ingestion, system can retrieve relevant content from the indexed book

- [ ] T014 [US3] Create Book ingestion schema in backend/src/models/book.py with Pydantic validation
- [ ] T015 [P] [US3] Implement PDF text extraction in backend/src/services/ingestion.py
- [ ] T016 [P] [US3] Implement HTML text extraction in backend/src/services/ingestion.py
- [ ] T017 [P] [US3] Implement TEXT file processing in backend/src/services/ingestion.py
- [ ] T018 [P] [US3] Create semantic chunking algorithm in backend/src/services/ingestion.py
- [ ] T019 [P] [US3] Create overlapping chunking algorithm in backend/src/services/ingestion.py
- [ ] T020 [P] [US3] Implement text preprocessing (cleaning, normalization) in backend/src/services/ingestion.py
- [ ] T021 [P] [US3] Implement file validation for upload in backend/src/api/routes/ingest.py
- [ ] T022 [US3] Create ingestion endpoint POST /ingest/upload in backend/src/api/routes/ingest.py
- [ ] T023 [US3] Implement book status tracking (PROCESSING, READY, ERROR) in backend/src/services/ingestion.py
- [ ] T024 [US3] Create status endpoint GET /ingest/status/{book_id} in backend/src/api/routes/ingest.py
- [ ] T025 [P] [US3] Connect embedding service to generate embeddings for chunks in backend/src/services/ingestion.py
- [ ] T026 [P] [US3] Connect storage service to store embeddings in Qdrant in backend/src/services/ingestion.py
- [ ] T027 [P] [US3] Connect storage service to store metadata in Neon Postgres in backend/src/services/ingestion.py
- [ ] T028 [P] [US3] Implement async processing for large files in backend/src/services/ingestion.py
- [ ] T029 [US3] Implement ingestion progress tracking in backend/src/services/ingestion.py

## Phase 4: User Story 1 - Query Full Book Content (Priority: P1)

**Goal**: Allow book reader to ask questions about the book and receive accurate, relevant answers based on entire book content

**Independent Test**: Upload a sample book, ingest its content, and ask broad questions about the book to verify system returns accurate answers based on the full book content.

**Acceptance**:
1. Book is successfully ingested and indexed
2. User asks a question about the book content and receives relevant, accurate answer based on entire book
3. Response generated within 2 seconds with citations to relevant book content
4. Response demonstrates knowledge from multiple parts of the book for questions requiring comprehensive understanding

- [ ] T030 [US1] Create full-book query schema in backend/src/models/query.py with Pydantic validation
- [ ] T031 [US1] Implement vector search in storage service backend/src/services/storage.py to retrieve relevant chunks
- [ ] T032 [P] [US1] Implement RAG orchestration service in backend/src/services/rag.py for full-book queries
- [ ] T033 [P] [US1] Create Cohere generation integration for full-book queries in backend/src/services/rag.py
- [ ] T034 [P] [US1] Implement response formatting with citations in backend/src/services/rag.py
- [ ] T035 [P] [US1] Create query history tracking in backend/src/services/rag.py
- [ ] T036 [US1] Create full-book query endpoint POST /query/full in backend/src/api/routes/query.py
- [ ] T037 [US1] Implement response time tracking in backend/src/services/rag.py
- [ ] T038 [US1] Implement token usage tracking in backend/src/services/rag.py
- [ ] T039 [US1] Implement query validation to ensure book exists and is ready in backend/src/api/routes/query.py
- [ ] T040 [US1] Add performance optimization to ensure <2s response time in backend/src/services/rag.py

## Phase 5: User Story 2 - Query Selected Text Only (Priority: P2)

**Goal**: Allow book reader to select specific text and ask questions only about that passage, with system responding exclusively based on the provided text

**Independent Test**: Select text passages and ask questions that would require full-book knowledge if answered correctly, verifying system responds only based on the selected text.

**Acceptance**:
1. User selects specific text in the book and asks related question
2. System responds based only on the selected text without referencing other parts of the book
3. For questions requiring knowledge outside selected text, system acknowledges limited scope and answers what can be inferred from selected text
4. Response generated within 2 seconds and strictly grounded in selected text

- [ ] T041 [US2] Create selected-text query schema in backend/src/models/query.py with Pydantic validation
- [ ] T042 [US2] Implement selected-text generation service in backend/src/services/rag.py
- [ ] T043 [US2] Create selected-text query endpoint POST /query/selected in backend/src/api/routes/query.py
- [ ] T044 [US2] Implement strict isolation to prevent knowledge bleed in backend/src/services/rag.py
- [ ] T045 [US2] Add validation to ensure selected text is not empty in backend/src/api/routes/query.py
- [ ] T046 [US2] Implement response formatting without citations in backend/src/services/rag.py (since no vector search is used)
- [ ] T047 [US2] Add performance optimization for selected-text mode in backend/src/services/rag.py

## Phase 6: Monitoring & Usage Tracking

- [ ] T048 Create usage monitoring script in backend/scripts/monitor_usage.py
- [ ] T049 Create monitoring endpoint GET /monitor/usage in backend/src/api/routes/monitor.py
- [ ] T050 Create system health endpoint GET /monitor/status in backend/src/api/routes/monitor.py
- [ ] T051 Implement Qdrant usage tracking in backend/scripts/monitor_usage.py
- [ ] T052 Implement Neon Postgres usage tracking in backend/scripts/monitor_usage.py
- [ ] T053 Add usage alerting when approaching limits in backend/scripts/monitor_usage.py

## Phase 7: Testing & Verification

- [ ] T054 Write unit tests for ingestion service backend/tests/unit/test_ingestion.py
- [ ] T055 Write unit tests for embedding service backend/tests/unit/test_embedding.py
- [ ] T056 Write unit tests for storage service backend/tests/unit/test_storage.py
- [ ] T057 Write unit tests for RAG service backend/tests/unit/test_rag.py
- [ ] T058 Write integration tests for full-book query flow backend/tests/integration/test_full_book_query.py
- [ ] T059 Write integration tests for selected-text query flow backend/tests/integration/test_selected_text_query.py
- [ ] T060 Write integration tests for ingestion flow backend/tests/integration/test_ingestion.py
- [ ] T061 Write contract tests for API endpoints backend/tests/contract/test_api_contracts.py
- [ ] T062 Implement response accuracy verification tests backend/tests/unit/test_response_accuracy.py
- [ ] T063 Create test dataset with sample books backend/tests/data/

## Phase 8: Documentation & Demo Preparation

- [ ] T064 Create comprehensive README.md with setup instructions
- [ ] T065 Prepare sample book for demo in backend/demo/
- [ ] T066 Create API documentation with usage examples
- [ ] T067 Document deployment instructions for different environments
- [ ] T068 Create troubleshooting guide for common issues

## Phase 9: Polish & Cross-Cutting Concerns

- [ ] T069 Add comprehensive error handling throughout the application
- [ ] T070 Add detailed logging for debugging and monitoring
- [ ] T071 Add proper exception handling and user-friendly messages
- [ ] T072 Optimize performance based on testing results
- [ ] T073 Review and enhance security measures
- [ ] T074 Conduct final system testing with sample books
- [ ] T075 Prepare final documentation and code cleanup

## Outcome

- ‚úÖ Impact: Created comprehensive task breakdown with 75 specific, actionable tasks organized by user story priority
- üß™ Tests: Added 10 testing-related tasks across unit, integration, and contract testing
- üìÅ Files: specs/001-integrated-rag-chatbot/tasks.md
- üîÅ Next prompts: /sp.implement to start the implementation based on these tasks
- üß† Reflection: Tasks follow the required checklist format with proper IDs, story labels, and file paths; dependencies between user stories are clearly identified

## Evaluation notes (flywheel)

- Failure modes observed: None
- Graders run and results (PASS/FAIL): PASS
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): Begin implementation with /sp.implement
