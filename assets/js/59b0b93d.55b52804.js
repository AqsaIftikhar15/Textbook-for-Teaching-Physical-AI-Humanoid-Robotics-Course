"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[4501],{5352:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction","items":[{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/","label":"Introduction","docId":"intro","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-1-ros2/week-1-2-intro-physical-ai","label":"Introduction to Physical AI","docId":"module-1-ros2/week-1-2-intro-physical-ai","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-1-ros2/week-3-ros2-fundamentals","label":"ROS 2 Fundamentals","docId":"module-1-ros2/week-3-ros2-fundamentals","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-1-ros2/week-4-advanced-ros2","label":"Advanced ROS 2 Concepts","docId":"module-1-ros2/week-4-advanced-ros2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-2-digital-twin/week-6-7-gazebo-unity","label":"Robot Simulation with Gazebo and Unity","docId":"module-2-digital-twin/week-6-7-gazebo-unity","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-2-digital-twin/simulation-concepts","label":"Simulation Concepts","docId":"module-2-digital-twin/simulation-concepts","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-3-ai-brain/week-8-10-isaac-platform","label":"NVIDIA Isaac Platform","docId":"module-3-ai-brain/week-8-10-isaac-platform","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-3-ai-brain/week-11-12-humanoid-dev","label":"Humanoid Robot Development","docId":"module-3-ai-brain/week-11-12-humanoid-dev","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-3-ai-brain/week-13-conversational-robotics","label":"Conversational Robotics Overview","docId":"module-3-ai-brain/week-13-conversational-robotics","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/week-13-vla-concepts","label":"Vision-Language-Action (VLA) Systems","docId":"module-4-vla/week-13-vla-concepts","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/week-13-vla-intro","label":"Introduction to Vision-Language-Action Systems","docId":"module-4-vla/week-13-vla-intro","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/week-14-voice-command-intro","label":"Introduction to Voice Command Processing in VLA Systems","docId":"module-4-vla/week-14-voice-command-intro","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/multimodal-integration-challenges","label":"Multimodal Integration Challenges in VLA Systems","docId":"module-4-vla/multimodal-integration-challenges","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/cross-modal-attention-math","label":"Mathematical Foundations of Cross-Modal Attention","docId":"module-4-vla/cross-modal-attention-math","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/gpt-model-applications","label":"GPT Model Applications in Voice-to-Action Translation","docId":"module-4-vla/gpt-model-applications","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/cognitive-planning-voice-commands","label":"Cognitive Planning for Voice-Driven Commands","docId":"module-4-vla/cognitive-planning-voice-commands","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/language-model-math","label":"Mathematical Foundations of Language Understanding Models","docId":"module-4-vla/language-model-math","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/hri-design-principles-intro","label":"Introduction to Human-Robot Interaction Design Principles","docId":"module-4-vla/hri-design-principles-intro","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/hri-speech-recognition","label":"Speech Recognition in Multimodal Interaction Systems","docId":"module-4-vla/hri-speech-recognition","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/gesture-vision-integration","label":"Gesture and Vision Integration in Human-Robot Interaction","docId":"module-4-vla/gesture-vision-integration","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/multimodal-fusion-math","label":"Mathematical Foundations of Multimodal Fusion","docId":"module-4-vla/multimodal-fusion-math","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/llm-possibilities-intro","label":"Introduction to Large Language Model Possibilities in Robotics","docId":"module-4-vla/llm-possibilities-intro","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/llm-limitations-robot-control","label":"Limitations of Large Language Models in Robot Control and Planning","docId":"module-4-vla/llm-limitations-robot-control","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/llm-safety-considerations","label":"Safety Considerations for LLM Integration in Robotics","docId":"module-4-vla/llm-safety-considerations","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/llm-uncertainty-math","label":"Mathematical Foundations of Uncertainty in LLM Outputs","docId":"module-4-vla/llm-uncertainty-math","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/vla-index","label":"Vision-Language-Action (VLA) Systems Index","docId":"module-4-vla/vla-index","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/vla-glossary","label":"VLA Terms Glossary","docId":"module-4-vla/vla-glossary","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/quick-reference-guides","label":"VLA Quick Reference Guides","docId":"module-4-vla/quick-reference-guides","unlisted":false},{"type":"link","href":"/Textbook-for-Teaching-Physical-AI-Humanoid-Robotics-Course/module-4-vla/phase-7-validation","label":"Phase 7 Validation Report - Navigation & Search","docId":"module-4-vla/phase-7-validation","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Introduction","description":"Welcome to the Physical AI & Humanoid Robotics Book","sidebar":"tutorialSidebar"},"module-1-ros2/week-1-2-intro-physical-ai":{"id":"module-1-ros2/week-1-2-intro-physical-ai","title":"Introduction to Physical AI","description":"Foundations of Physical AI and embodied intelligence","sidebar":"tutorialSidebar"},"module-1-ros2/week-3-ros2-fundamentals":{"id":"module-1-ros2/week-3-ros2-fundamentals","title":"ROS 2 Fundamentals","description":"Overview of ROS 2 middleware architecture","sidebar":"tutorialSidebar"},"module-1-ros2/week-4-advanced-ros2":{"id":"module-1-ros2/week-4-advanced-ros2","title":"Advanced ROS 2 Concepts","description":"Parameter management, launch files, and real-time control","sidebar":"tutorialSidebar"},"module-2-digital-twin/simulation-concepts":{"id":"module-2-digital-twin/simulation-concepts","title":"Simulation Concepts","description":"Core concepts in physics simulation and digital twins","sidebar":"tutorialSidebar"},"module-2-digital-twin/week-6-7-gazebo-unity":{"id":"module-2-digital-twin/week-6-7-gazebo-unity","title":"Robot Simulation with Gazebo and Unity","description":"Physics simulation and environment building","sidebar":"tutorialSidebar"},"module-3-ai-brain/week-11-12-humanoid-dev":{"id":"module-3-ai-brain/week-11-12-humanoid-dev","title":"Humanoid Robot Development","description":"Kinematics, dynamics, and locomotion for humanoid robots","sidebar":"tutorialSidebar"},"module-3-ai-brain/week-13-conversational-robotics":{"id":"module-3-ai-brain/week-13-conversational-robotics","title":"Conversational Robotics Overview","description":"Integrating GPT models for conversational AI in robots","sidebar":"tutorialSidebar"},"module-3-ai-brain/week-8-10-isaac-platform":{"id":"module-3-ai-brain/week-8-10-isaac-platform","title":"NVIDIA Isaac Platform","description":"AI-powered perception and manipulation with Isaac SDK","sidebar":"tutorialSidebar"},"module-4-vla/cognitive-planning-voice-commands":{"id":"module-4-vla/cognitive-planning-voice-commands","title":"Cognitive Planning for Voice-Driven Commands","description":"Understanding principles of planning for voice-activated robot behaviors","sidebar":"tutorialSidebar"},"module-4-vla/cross-modal-attention-math":{"id":"module-4-vla/cross-modal-attention-math","title":"Mathematical Foundations of Cross-Modal Attention","description":"Detailed mathematical explanation of cross-modal attention mechanisms in VLA systems","sidebar":"tutorialSidebar"},"module-4-vla/diagrams/llm-robotics-integration":{"id":"module-4-vla/diagrams/llm-robotics-integration","title":"LLM Integration in Robotics Diagram","description":"Diagram Information"},"module-4-vla/diagrams/multimodal-interaction-system":{"id":"module-4-vla/diagrams/multimodal-interaction-system","title":"Multimodal Interaction System Diagram","description":"Diagram Information"},"module-4-vla/diagrams/vla-system-architecture":{"id":"module-4-vla/diagrams/vla-system-architecture","title":"VLA System Architecture Diagram","description":"Diagram Information"},"module-4-vla/diagrams/voice-to-action-pipeline":{"id":"module-4-vla/diagrams/voice-to-action-pipeline","title":"Voice-to-Action Pipeline Diagram","description":"Diagram Information"},"module-4-vla/gesture-vision-integration":{"id":"module-4-vla/gesture-vision-integration","title":"Gesture and Vision Integration in Human-Robot Interaction","description":"Understanding how gesture recognition and visual perception work together in multimodal interaction","sidebar":"tutorialSidebar"},"module-4-vla/gpt-model-applications":{"id":"module-4-vla/gpt-model-applications","title":"GPT Model Applications in Voice-to-Action Translation","description":"Understanding how GPT models translate natural language into robot action sequences","sidebar":"tutorialSidebar"},"module-4-vla/hri-design-principles-intro":{"id":"module-4-vla/hri-design-principles-intro","title":"Introduction to Human-Robot Interaction Design Principles","description":"Understanding fundamental principles for effective human-robot interaction design","sidebar":"tutorialSidebar"},"module-4-vla/hri-speech-recognition":{"id":"module-4-vla/hri-speech-recognition","title":"Speech Recognition in Multimodal Interaction Systems","description":"Understanding speech processing within multimodal human-robot interaction","sidebar":"tutorialSidebar"},"module-4-vla/language-model-math":{"id":"module-4-vla/language-model-math","title":"Mathematical Foundations of Language Understanding Models","description":"Detailed mathematical explanation of embeddings, attention mechanisms, and probability distributions in language models","sidebar":"tutorialSidebar"},"module-4-vla/llm-limitations-robot-control":{"id":"module-4-vla/llm-limitations-robot-control","title":"Limitations of Large Language Models in Robot Control and Planning","description":"Understanding critical limitations of LLMs for robotic applications","sidebar":"tutorialSidebar"},"module-4-vla/llm-possibilities-intro":{"id":"module-4-vla/llm-possibilities-intro","title":"Introduction to Large Language Model Possibilities in Robotics","description":"Understanding potential applications of LLMs in robotic systems","sidebar":"tutorialSidebar"},"module-4-vla/llm-safety-considerations":{"id":"module-4-vla/llm-safety-considerations","title":"Safety Considerations for LLM Integration in Robotics","description":"Understanding critical safety measures for integrating LLMs with robotic systems","sidebar":"tutorialSidebar"},"module-4-vla/llm-uncertainty-math":{"id":"module-4-vla/llm-uncertainty-math","title":"Mathematical Foundations of Uncertainty in LLM Outputs","description":"Detailed mathematical explanation of uncertainty quantification in LLM outputs for robotics","sidebar":"tutorialSidebar"},"module-4-vla/multimodal-fusion-math":{"id":"module-4-vla/multimodal-fusion-math","title":"Mathematical Foundations of Multimodal Fusion","description":"Detailed mathematical explanation of multimodal integration and fusion mechanisms","sidebar":"tutorialSidebar"},"module-4-vla/multimodal-integration-challenges":{"id":"module-4-vla/multimodal-integration-challenges","title":"Multimodal Integration Challenges in VLA Systems","description":"Understanding challenges in vision-language coordination and motor planning","sidebar":"tutorialSidebar"},"module-4-vla/phase-3-validation":{"id":"module-4-vla/phase-3-validation","title":"Phase 3 Content Validation Report","description":"Overview"},"module-4-vla/phase-4-validation":{"id":"module-4-vla/phase-4-validation","title":"Phase 4 Content Validation Report","description":"Overview"},"module-4-vla/phase-5-validation":{"id":"module-4-vla/phase-5-validation","title":"Phase 5 Content Validation Report","description":"Overview"},"module-4-vla/phase-6-validation":{"id":"module-4-vla/phase-6-validation","title":"Phase 6 Content Validation Report","description":"Overview"},"module-4-vla/phase-7-validation":{"id":"module-4-vla/phase-7-validation","title":"Phase 7 Validation Report - Navigation & Search","description":"Validation report for VLA module navigation and search functionality","sidebar":"tutorialSidebar"},"module-4-vla/phase-8-final-quality-checklist":{"id":"module-4-vla/phase-8-final-quality-checklist","title":"Phase 8 Final Academic Quality Validation Checklist: Vision-Language-Action (VLA) Module","description":"Validation Overview"},"module-4-vla/phase-8-pedagogical-review":{"id":"module-4-vla/phase-8-pedagogical-review","title":"Phase 8 Pedagogical Review: Vision-Language-Action (VLA) Module","description":"Review Overview"},"module-4-vla/phase-8-publication-approval":{"id":"module-4-vla/phase-8-publication-approval","title":"Phase 8 Publication Approval: Vision-Language-Action (VLA) Module","description":"Publication Overview"},"module-4-vla/phase-8-technical-review":{"id":"module-4-vla/phase-8-technical-review","title":"Phase 8 Technical Review: Vision-Language-Action (VLA) Module","description":"Review Overview"},"module-4-vla/pseudocode/llm-robot-interaction":{"id":"module-4-vla/pseudocode/llm-robot-interaction","title":"LLM-Robot Interaction Pseudo-Code Example","description":"Example Information"},"module-4-vla/pseudocode/multimodal-input-processing":{"id":"module-4-vla/pseudocode/multimodal-input-processing","title":"Multimodal Input Processing Pseudo-Code Example","description":"Example Information"},"module-4-vla/pseudocode/vla-workflow-example":{"id":"module-4-vla/pseudocode/vla-workflow-example","title":"VLA Workflow Integration Pseudo-Code Example","description":"Example Information"},"module-4-vla/pseudocode/voice-command-to-action":{"id":"module-4-vla/pseudocode/voice-command-to-action","title":"Voice Command to Action Mapping Pseudo-Code Example","description":"Example Information"},"module-4-vla/quick-reference-guides":{"id":"module-4-vla/quick-reference-guides","title":"VLA Quick Reference Guides","description":"One-page reference guides for key VLA concepts and processes","sidebar":"tutorialSidebar"},"module-4-vla/references":{"id":"module-4-vla/references","title":"VLA Module References","description":"Overview"},"module-4-vla/review-process":{"id":"module-4-vla/review-process","title":"VLA Module Content Review Process","description":"Overview"},"module-4-vla/templates/diagram-template":{"id":"module-4-vla/templates/diagram-template","title":"Conceptual Diagram Template","description":"Diagram Information"},"module-4-vla/templates/pseudocode-template":{"id":"module-4-vla/templates/pseudocode-template","title":"Pseudo-Code Example Template","description":"Example Information"},"module-4-vla/vla-concepts-data-model":{"id":"module-4-vla/vla-concepts-data-model","title":"VLA (Vision-Language-Action) Concepts Data Model","description":"Overview"},"module-4-vla/vla-glossary":{"id":"module-4-vla/vla-glossary","title":"VLA Terms Glossary","description":"Comprehensive glossary of Vision-Language-Action (VLA) system terminology","sidebar":"tutorialSidebar"},"module-4-vla/vla-index":{"id":"module-4-vla/vla-index","title":"Vision-Language-Action (VLA) Systems Index","description":"Comprehensive alphabetical index of all VLA concepts, terms, and topics","sidebar":"tutorialSidebar"},"module-4-vla/week-13-vla-concepts":{"id":"module-4-vla/week-13-vla-concepts","title":"Vision-Language-Action (VLA) Systems","description":"Understanding multimodal integration of vision, language, and motor actions","sidebar":"tutorialSidebar"},"module-4-vla/week-13-vla-intro":{"id":"module-4-vla/week-13-vla-intro","title":"Introduction to Vision-Language-Action Systems","description":"Understanding the fundamentals of VLA systems for humanoid robotics","sidebar":"tutorialSidebar"},"module-4-vla/week-14-voice-command-intro":{"id":"module-4-vla/week-14-voice-command-intro","title":"Introduction to Voice Command Processing in VLA Systems","description":"Understanding how voice commands are processed and translated into robot actions","sidebar":"tutorialSidebar"}}}}')}}]);